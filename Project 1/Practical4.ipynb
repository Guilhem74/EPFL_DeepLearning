{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Using MNIST\n",
      "** Reduce the data-set (use --full for the full thing)\n",
      "** Use 1000 train and 1000 test samples\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "######################################################################\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import dlc_practical_prologue as prologue\n",
    "\n",
    "train_input, train_target, test_input, test_target = \\\n",
    "    prologue.load_data(one_hot_labels = True, normalize = True, flatten = False)\n",
    "\n",
    "######################################################################\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, nb_hidden):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(256, nb_hidden)\n",
    "        self.fc2 = nn.Linear(nb_hidden, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=3, stride=3))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), kernel_size=2, stride=2))\n",
    "        x = F.relu(self.fc1(x.view(-1, 256)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class Net2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net2, self).__init__()\n",
    "        nb_hidden = 200\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=5)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=2)\n",
    "        self.fc1 = nn.Linear(9 * 64, nb_hidden)\n",
    "        self.fc2 = nn.Linear(nb_hidden, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), kernel_size=2))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.fc1(x.view(-1, 9 * 64)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "######################################################################\n",
    "\n",
    "def train_model(model, train_input, train_target, mini_batch_size):\n",
    "    criterion = nn.MSELoss()\n",
    "    eta = 1e-1\n",
    "\n",
    "    for e in range(25):\n",
    "        sum_loss = 0\n",
    "        for b in range(0, train_input.size(0), mini_batch_size):\n",
    "            output = model(train_input.narrow(0, b, mini_batch_size))\n",
    "            loss = criterion(output, train_target.narrow(0, b, mini_batch_size))\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            sum_loss = sum_loss + loss.item()\n",
    "            for p in model.parameters():\n",
    "                p.data.sub_(eta * p.grad.data)\n",
    "        print(e, sum_loss)\n",
    "\n",
    "def compute_nb_errors(model, input, target, mini_batch_size):\n",
    "    nb_errors = 0\n",
    "\n",
    "    for b in range(0, input.size(0), mini_batch_size):\n",
    "        output = model(input.narrow(0, b, mini_batch_size))\n",
    "        _, predicted_classes = output.data.max(1)\n",
    "        for k in range(mini_batch_size):\n",
    "            if target.data[b + k, predicted_classes[k]] <= 0:\n",
    "                nb_errors = nb_errors + 1\n",
    "\n",
    "    return nb_errors\n",
    "\n",
    "######################################################################\n",
    "\n",
    "train_input, train_target = Variable(train_input), Variable(train_target)\n",
    "test_input, test_target = Variable(test_input), Variable(test_target)\n",
    "\n",
    "mini_batch_size = 100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1753,  0.1998, -0.0236,  0.0704, -0.2347, -0.1632, -0.0874,  0.2934,\n",
      "          0.3089,  0.1217],\n",
      "        [-0.2045,  0.1267, -0.0427,  0.0299, -0.1113, -0.1951, -0.0818,  0.2626,\n",
      "          0.3525,  0.0232],\n",
      "        [-0.1438,  0.1126, -0.0956,  0.0878, -0.1515, -0.1192, -0.2036,  0.1890,\n",
      "          0.2791, -0.0186],\n",
      "        [-0.0929,  0.1717, -0.0874,  0.1586, -0.1968, -0.2009, -0.1561,  0.2471,\n",
      "          0.3413,  0.0180],\n",
      "        [-0.1788,  0.1257, -0.0268,  0.1488, -0.2316, -0.1226, -0.1106,  0.2372,\n",
      "          0.3825,  0.0816],\n",
      "        [-0.1725,  0.1374, -0.0630,  0.0846, -0.2475, -0.1885, -0.1812,  0.2744,\n",
      "          0.3500,  0.0585],\n",
      "        [-0.0567,  0.0805, -0.0089,  0.1277, -0.2593, -0.1145, -0.0545,  0.2315,\n",
      "          0.2504,  0.0784],\n",
      "        [-0.1943,  0.1483, -0.0687,  0.1447, -0.2043, -0.1678, -0.1447,  0.2742,\n",
      "          0.3757, -0.0280],\n",
      "        [-0.0785,  0.0963, -0.0604,  0.1263, -0.2002, -0.1310, -0.0764,  0.1963,\n",
      "          0.2089,  0.0876],\n",
      "        [-0.1607,  0.1308, -0.0528,  0.1498, -0.2132, -0.1653, -0.1940,  0.2719,\n",
      "          0.3594, -0.0271]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "model = Net(200)\n",
    "output = model(train_input.narrow(0, 0, 10))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.9223078563809395\n",
      "1 0.799484483897686\n",
      "2 0.7354758158326149\n",
      "3 0.6770432069897652\n",
      "4 0.6261134333908558\n",
      "5 0.5847308896481991\n",
      "6 0.5515117049217224\n",
      "7 0.5181113034486771\n",
      "8 0.48692817986011505\n",
      "9 0.47050345316529274\n",
      "10 0.44845792278647423\n",
      "11 0.4096074551343918\n",
      "12 0.4355189576745033\n",
      "13 0.38822848722338676\n",
      "14 0.3605176918208599\n",
      "15 0.3519678916782141\n",
      "16 0.3524400033056736\n",
      "17 0.34168546460568905\n",
      "18 0.3179338909685612\n",
      "19 0.31725407764315605\n",
      "20 0.3159294296056032\n",
      "21 0.2932353727519512\n",
      "22 0.29531256668269634\n",
      "23 0.2801944874227047\n",
      "24 0.2756394650787115\n",
      "test error Net 13.80% 138/1000\n",
      "0 0.9162067696452141\n",
      "1 0.7941851168870926\n",
      "2 0.7182531803846359\n",
      "3 0.6506625637412071\n",
      "4 0.5935915857553482\n",
      "5 0.5465456806123257\n",
      "6 0.5118890851736069\n",
      "7 0.497282300144434\n",
      "8 0.49226564541459084\n",
      "9 0.43021615967154503\n",
      "10 0.44787009060382843\n",
      "11 0.39254794269800186\n",
      "12 0.3764522485435009\n",
      "13 0.3685768209397793\n",
      "14 0.3500896282494068\n",
      "15 0.33492385037243366\n",
      "16 0.32696438021957874\n",
      "17 0.3153888452798128\n",
      "18 0.2974718548357487\n",
      "19 0.2893424555659294\n",
      "20 0.3046603687107563\n",
      "21 0.2832991760224104\n",
      "22 0.2753141466528177\n",
      "23 0.2632978744804859\n",
      "24 0.2557810451835394\n",
      "test error Net 13.40% 134/1000\n",
      "0 0.9025499448180199\n",
      "1 0.7989912927150726\n",
      "2 0.7295419052243233\n",
      "3 0.6691255643963814\n",
      "4 0.6155085489153862\n",
      "5 0.5691361762583256\n",
      "6 0.530043613165617\n",
      "7 0.4986003115773201\n",
      "8 0.47242481261491776\n",
      "9 0.44876833632588387\n",
      "10 0.4255317822098732\n",
      "11 0.40706097707152367\n",
      "12 0.40659787878394127\n",
      "13 0.3794311098754406\n",
      "14 0.3525976277887821\n",
      "15 0.35227667540311813\n",
      "16 0.34629064053297043\n",
      "17 0.32198893278837204\n",
      "18 0.31052169390022755\n",
      "19 0.308439576998353\n",
      "20 0.30182525515556335\n",
      "21 0.29854583740234375\n",
      "22 0.29933459497988224\n",
      "23 0.27119413763284683\n",
      "24 0.2675617914646864\n",
      "test error Net 14.30% 143/1000\n",
      "0 0.8784107118844986\n",
      "1 0.7740884870290756\n",
      "2 0.7063710540533066\n",
      "3 0.645049437880516\n",
      "4 0.5924261808395386\n",
      "5 0.5482640117406845\n",
      "6 0.5126721747219563\n",
      "7 0.48624080419540405\n",
      "8 0.46650244295597076\n",
      "9 0.4390548802912235\n",
      "10 0.43195292726159096\n",
      "11 0.42658716812729836\n",
      "12 0.40795275941491127\n",
      "13 0.385099682956934\n",
      "14 0.35645548440515995\n",
      "15 0.3516390882432461\n",
      "16 0.33894521929323673\n",
      "17 0.322448855265975\n",
      "18 0.3212677091360092\n",
      "19 0.32000915706157684\n",
      "20 0.29587691836059093\n",
      "21 0.31454527378082275\n",
      "22 0.2911390122026205\n",
      "23 0.28235089778900146\n",
      "24 0.2854164745658636\n",
      "test error Net 13.10% 131/1000\n",
      "0 0.9414958953857422\n",
      "1 0.7861912772059441\n",
      "2 0.7190099433064461\n",
      "3 0.6600227952003479\n",
      "4 0.6083940006792545\n",
      "5 0.5633190311491489\n",
      "6 0.5286252088844776\n",
      "7 0.563006553798914\n",
      "8 0.4789859913289547\n",
      "9 0.4514544904232025\n",
      "10 0.4487009420990944\n",
      "11 0.4250802844762802\n",
      "12 0.3940899781882763\n",
      "13 0.38260481506586075\n",
      "14 0.40504247322678566\n",
      "15 0.36378631368279457\n",
      "16 0.3436353299766779\n",
      "17 0.3555170614272356\n",
      "18 0.33436804823577404\n",
      "19 0.31365277245640755\n",
      "20 0.30709160305559635\n",
      "21 0.30644306540489197\n",
      "22 0.30001056380569935\n",
      "23 0.29589225724339485\n",
      "24 0.28030314669013023\n",
      "test error Net 15.00% 150/1000\n",
      "0 0.9290789216756821\n",
      "1 0.807010754942894\n",
      "2 0.7397433891892433\n",
      "3 0.6742064133286476\n",
      "4 0.61433045566082\n",
      "5 0.5659167245030403\n",
      "6 0.5286293439567089\n",
      "7 0.5054692886769772\n",
      "8 0.4869171492755413\n",
      "9 0.4497726894915104\n",
      "10 0.4601326808333397\n",
      "11 0.41305599734187126\n",
      "12 0.3901454210281372\n",
      "13 0.38536544144153595\n",
      "14 0.3628978170454502\n",
      "15 0.3492320869117975\n",
      "16 0.3629811331629753\n",
      "17 0.33824534714221954\n",
      "18 0.3294552378356457\n",
      "19 0.3017601389437914\n",
      "20 0.3199906926602125\n",
      "21 0.2999689616262913\n",
      "22 0.2821948677301407\n",
      "23 0.2813028655946255\n",
      "24 0.26519797928631306\n",
      "test error Net 12.90% 129/1000\n",
      "0 0.9385503530502319\n",
      "1 0.8375754058361053\n",
      "2 0.7760641947388649\n",
      "3 0.7187306955456734\n",
      "4 0.6657711416482925\n",
      "5 0.6176091022789478\n",
      "6 0.5750266686081886\n",
      "7 0.5388083793222904\n",
      "8 0.5088598616421223\n",
      "9 0.48480457067489624\n",
      "10 0.4677414521574974\n",
      "11 0.45356111973524094\n",
      "12 0.4329736642539501\n",
      "13 0.41524894535541534\n",
      "14 0.40094227716326714\n",
      "15 0.3829750567674637\n",
      "16 0.36551881581544876\n",
      "17 0.3556437771767378\n",
      "18 0.3763870447874069\n",
      "19 0.34940030239522457\n",
      "20 0.3155733086168766\n",
      "21 0.305188013240695\n",
      "22 0.31564384140074253\n",
      "23 0.3106804732233286\n",
      "24 0.2863993067294359\n",
      "test error Net 19.60% 196/1000\n",
      "0 0.9069949686527252\n",
      "1 0.8255410492420197\n",
      "2 0.7753181234002113\n",
      "3 0.7279815003275871\n",
      "4 0.6813600063323975\n",
      "5 0.6363180130720139\n",
      "6 0.5945910029113293\n",
      "7 0.5582666844129562\n",
      "8 0.5280067659914494\n",
      "9 0.5030113980174065\n",
      "10 0.48222339898347855\n",
      "11 0.46202707290649414\n",
      "12 0.44209521263837814\n",
      "13 0.42297909408807755\n",
      "14 0.4065072759985924\n",
      "15 0.39488986879587173\n",
      "16 0.3919486552476883\n",
      "17 0.3647031597793102\n",
      "18 0.35023351199924946\n",
      "19 0.3656264990568161\n",
      "20 0.3293711319565773\n",
      "21 0.3163670487701893\n",
      "22 0.31032119132578373\n",
      "23 0.3217478096485138\n",
      "24 0.3071341775357723\n",
      "test error Net 15.90% 159/1000\n",
      "0 0.9085213541984558\n",
      "1 0.7813666686415672\n",
      "2 0.7026701122522354\n",
      "3 0.6360621564090252\n",
      "4 0.5841631293296814\n",
      "5 0.54957315325737\n",
      "6 0.522845271974802\n",
      "7 0.49003999307751656\n",
      "8 0.46397603303194046\n",
      "9 0.44605401903390884\n",
      "10 0.43182776123285294\n",
      "11 0.423808928579092\n",
      "12 0.40105170756578445\n",
      "13 0.37947435304522514\n",
      "14 0.3575040213763714\n",
      "15 0.33803858049213886\n",
      "16 0.3257727827876806\n",
      "17 0.3208997808396816\n",
      "18 0.3250600006431341\n",
      "19 0.2968591246753931\n",
      "20 0.29079549573361874\n",
      "21 0.3046046197414398\n",
      "22 0.2714715078473091\n",
      "23 0.2621299438178539\n",
      "24 0.27163015492260456\n",
      "test error Net 14.80% 148/1000\n",
      "0 0.9285266548395157\n",
      "1 0.8070313185453415\n",
      "2 0.7383511513471603\n",
      "3 0.6791504323482513\n",
      "4 0.6267293281853199\n",
      "5 0.5823673792183399\n",
      "6 0.5475894026458263\n",
      "7 0.5341108441352844\n",
      "8 0.5062929317355156\n",
      "9 0.46650024875998497\n",
      "10 0.44955943897366524\n",
      "11 0.46772443130612373\n",
      "12 0.4132184237241745\n",
      "13 0.41728902608156204\n",
      "14 0.38397109508514404\n",
      "15 0.3752922900021076\n",
      "16 0.37610698491334915\n",
      "17 0.34246184304356575\n",
      "18 0.33824835903942585\n",
      "19 0.33783324621617794\n",
      "20 0.35400055162608624\n",
      "21 0.32074861973524094\n",
      "22 0.29640356451272964\n",
      "23 0.3040883503854275\n",
      "24 0.2884857766330242\n",
      "test error Net 14.30% 143/1000\n"
     ]
    }
   ],
   "source": [
    "######################################################################\n",
    "# Question 2\n",
    "\n",
    "for k in range(10):\n",
    "    model = Net(200)\n",
    "    train_model(model, train_input, train_target, mini_batch_size)\n",
    "    nb_test_errors = compute_nb_errors(model, test_input, test_target, mini_batch_size)\n",
    "    print('test error Net {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors) / test_input.size(0),\n",
    "                                                      nb_test_errors, test_input.size(0)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "######################################################################\n",
    "# Question 3\n",
    "\n",
    "for nh in [ 10, 50, 200, 500, 2500 ]:\n",
    "    model = Net(nh)\n",
    "    train_model(model, train_input, train_target, mini_batch_size)\n",
    "    nb_test_errors = compute_nb_errors(model, test_input, test_target, mini_batch_size)\n",
    "    print('test error Net nh={:d} {:0.2f}%% {:d}/{:d}'.format(nh,\n",
    "                                                              (100 * nb_test_errors) / test_input.size(0),\n",
    "                                                              nb_test_errors, test_input.size(0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# Question 4\n",
    "\n",
    "model = Net2()\n",
    "train_model(model, train_input, train_target, mini_batch_size)\n",
    "nb_test_errors = compute_nb_errors(model, test_input, test_target, mini_batch_size)\n",
    "print('test error Net2 {:0.2f}%% {:d}/{:d}'.format((100 * nb_test_errors) / test_input.size(0),\n",
    "                                                   nb_test_errors, test_input.size(0)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
