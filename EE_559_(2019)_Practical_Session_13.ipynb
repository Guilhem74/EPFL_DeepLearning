{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EE-559 (2019): Practical Session 13",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "JndnmDMp66FL"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Guilhem74/EPFL_DeepLearning/blob/master/EE_559_(2019)_Practical_Session_13.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvkIGwGFr2ci",
        "colab_type": "text"
      },
      "source": [
        "This Colab is the practical part of the 13th Session \"TensorFlow Introduction\" (guest lecture by Andreas Steiner) in Fran√ßois Fleuret's Deep Learning Course (https://fleuret.org/ee559)\n",
        "\n",
        "Please refer to the handout for instructions about the exercises:\n",
        "\n",
        "https://docs.google.com/document/d/1dWLM0bRu0qW_B2cKJSisZghUBQ-x-ZBE19TWKmvv_hQ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JndnmDMp66FL",
        "colab_type": "text"
      },
      "source": [
        "##### Copyright 2019 Google LLC.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMqWDc_m6rUC",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Q8g2GTn32AR",
        "colab_type": "text"
      },
      "source": [
        "# 0 Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfqC7r_kIIeQ",
        "colab_type": "text"
      },
      "source": [
        "## 0.1 Authenticate\n",
        "\n",
        "We need to access both GCS (Google cloud storage) for getting the prepared QuickDraw data and Google Drive for storing data beyond the short lifetime of the virtual machine running the kernel for this Colab.\n",
        "\n",
        "Below cell runs the authentication workflow for both GCS & Drive. Needs to be re-executed every time the VM is restarted."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBkULW3YIKf3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3knFMfGhxh_d",
        "colab_type": "text"
      },
      "source": [
        "## 0.2 Install & import\n",
        "\n",
        "By default, TensorFlow 1.13 is installed. But we're going to use the alpha version of TensorFlow 2.0 which first needs to be installed on the machine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzjHkgoMap24",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's install GPU that runs fine on both CPU and GPU.\n",
        "!pip install -q tf-nightly-gpu-2.0-preview"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzMYG9DXac92",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "if int(tf.__version__.split('.')[0]) < 2:\n",
        "    tf.enable_eager_execution()\n",
        "(tf.__version__, tf.test.is_gpu_available(), 'COLAB_TPU_ADDR' in os.environ)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCKwIEmrbzQt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json, os, time\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# We will store models on Drive.\n",
        "models_path = '/content/gdrive/My Drive/ee559/session13/models'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAOJ3HzkwOym",
        "colab_type": "text"
      },
      "source": [
        "# 1 Colab\n",
        "\n",
        "If you use Python on a regular basis, you're probably already familiar with [Jupyter Notebook](https://jupyter.org/). Colab is a basically a Jupyter notebook in the cloud : the notebook itself is stored as a Google doc (with revision history, access control, comments, and concurrent editing) and the Python kernel runs in a dynamically allocated virtual machine on Google cloud.\n",
        "\n",
        "The web UI is also somewhat improved, including a left-hand drawer with table of contents, snippets, and remote file browser. There are also custom extensions, \"forms\" and much more."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Din_y8YSwPZ3",
        "colab_type": "text"
      },
      "source": [
        "## 1.1 Important shortcuts\n",
        "\n",
        "Action | Colab Shortcut | Jupyter Shortcut\n",
        "---|---|---\n",
        "Executes current cell | `<CTRL-ENTER>` | `<CTRL-ENTER>`\n",
        "Executes current cell and moves to next cell | `<SHIFT-ENTER>` | `<SHIFT-ENTER>`\n",
        "Insert cell above | `<CTRL-M> <A>` | `<A>`\n",
        "Append cell below | `<CTRL-M> <B>` | `<B>`\n",
        "Shows searchable command palette | `<CTRL-SHIFT-P>` | `<CTRL-SHIFT-P>`\n",
        "Convert cell to code | `<CTRL-M> <Y>` | `<Y>`\n",
        "Convert cell to Markdown | `<CTRL-M> <M>` | `<M>`\n",
        "Autocomplete | `<TAB>` | `<TAB>`\n",
        "Goes from edit to \"command\" mode | `<ESC>` | `<ESC>`\n",
        "Goes from \"command\" to edit mode | `<ENTER>` | `<ENTER>`\n",
        "Show keyboard shortcuts | `<CTRL-M> <H>` | `<H>`\n",
        "<p align=\"center\"><b>Note:</b> On OS X you can use `<COMMAND>` instead of `<CTRL>`</p>\n",
        "\n",
        "Give it a try!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JNFoJ7XAYai",
        "colab_type": "text"
      },
      "source": [
        "## 1.1 API documentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RWqC8rzAaXK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Place the caret inside the parens and hit <TAB> to get a popover displaying\n",
        "# the API documentation. So useful it merits its very own section in this Colab.\n",
        "tf.GradientTape()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mahgn1AHL61",
        "colab_type": "text"
      },
      "source": [
        "## 1.2 About runtimes\n",
        "\n",
        "Colab provides multiple runtimes with different hardware accelerators:\n",
        "\n",
        "*   CPU (default)\n",
        "*   GPU\n",
        "*   TPU\n",
        "\n",
        "which can be selected by choosing the `\"Runtime\"` tab above and then `\"Change runtime type\"`.\n",
        "\n",
        "Please be aware that selecting a new runtime will assign a new virtual machine (VM).\n",
        "In general, assume that any changes you make to the VM environment including data storage are **ephemeral**. Particularly, this might require to **execute previous cells again** as their content is unknown to a new runtime otherwise. \n",
        "\n",
        "Let's take a closer look at one of such provided VMs.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwLSimGKgHFd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Display how long the system has been running.\n",
        "!uptime"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saP-n9oMwdyF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Display available and used memory.\n",
        "!free -h\n",
        "print(\"-\"*70)\n",
        "# Display the CPU specification.\n",
        "!lscpu\n",
        "print(\"-\"*70)\n",
        "# Display the GPU specification (if available).\n",
        "!(nvidia-smi | grep -q \"has failed\") && echo \"No GPU found!\" || nvidia-smi "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSeWPxoz9B4j",
        "colab_type": "text"
      },
      "source": [
        "## 1.3 Start TensorBoard & tunnel\n",
        "\n",
        "We can start arbitrary programs in our VM. One particularly interesting program is [TensorBoard](https://www.tensorflow.org/guide/summaries_and_tensorboard) allows to track metrics during training (and much more).\n",
        "\n",
        "Unfortunately, the VM's ports cannot be accessed directly from the web, so we have to tunnel them via a service. The example below uses https://ngrok.com/ whose utility first must be downloaded."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KflbtzMLckFt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download & unzip ngrok\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip -o ngrok-stable-linux-amd64.zip\n",
        "!ls -lh ./ngrok"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Gt66EpxiGb5F",
        "colab": {}
      },
      "source": [
        "# This cell (re)starts TensorBoard & forward the port using ngrok.\n",
        "\n",
        "# Stop previously started processes, if any.\n",
        "!pkill tensorboard; pkill ngrok\n",
        "# Make sure ngrok was installed locally in previous cell.\n",
        "assert os.system('./ngrok --help') == 0\n",
        "# Start TensorBoard.\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir \"./tensorboard\" --host 0.0.0.0 --port 6006 &'\n",
        ")\n",
        "# Forward port.\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "# Give some time to start up.\n",
        "!sleep 1\n",
        "# Output external address (ngrok's web interface listens at 4004).\n",
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9nnz_0b9OG4",
        "colab_type": "text"
      },
      "source": [
        "Note that you can also start this process in a separate Colab running on the same VM : Create a new Colab \"File/New Python 3 Notebook\" copy above cell and paste it into the new Colab. Since both Colabs run in the same VM (unless they have a different setting \"Runtime/Change runtime type\") you don't need to download ngrok, it is already in the current working directory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNXXTWiMA8hn",
        "colab_type": "text"
      },
      "source": [
        "### 1.4 More ...\n",
        "\n",
        "We've only covered the very basics about Colab in above sections. If you're interested in knowing more, please check out the Colab [0_colab.ipynb](https://colab.research.google.com/github/tensorflow/workshops/blob/master/extras/amld/notebooks/solutions/0_colab.ipynb) from the AMLD workshop, or walk through some of the example Colabs (File/Open -> select from \"Examples\" tab).\n",
        "\n",
        "(But try not to spend more than 10 minutes overall in this \"Colab\" section)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWG6zleTcDJr",
        "colab_type": "text"
      },
      "source": [
        "# 2 Predicting QuickDraw\n",
        "\n",
        "In this section we will train some simple models on [QuickDraw data](https://quickdraw.withgoogle.com/data/). The purpose is to familiarize you with basic TensorFlow API and Keras, so you can come back to these examples later on and use them as a skeleton when building your own models.\n",
        "\n",
        "The code is a short summary the following AMLD Workshop notebooks - go there for more in depth examples:\n",
        "\n",
        "https://colab.research.google.com/github/tensorflow/workshops/blob/master/extras/amld/notebooks/solutions/1_data.ipynb\n",
        "\n",
        "https://colab.research.google.com/github/tensorflow/workshops/blob/master/extras/amld/notebooks/solutions/2_keras.ipynb\n",
        "\n",
        "https://colab.research.google.com/github/tensorflow/workshops/blob/master/extras/amld/notebooks/solutions/3_eager.ipynb\n",
        "\n",
        "https://colab.research.google.com/github/tensorflow/workshops/blob/master/extras/amld/notebooks/solutions/4_predict.ipynb\n",
        "\n",
        "(Be aware that those notebooks are still using TensorFlow 1.13)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLGR9_iauMbO",
        "colab_type": "text"
      },
      "source": [
        "## 2.1 Read data\n",
        "\n",
        "Today we're using a prepared dataset in [protocol buffer](https://developers.google.com/protocol-buffers/docs/pythontutorial) format on Cloud. Preparing your own data is an interesting topic and described in some length in the [AMLD workshop](https://github.com/tensorflow/workshops/tree/master/extras/amld).\n",
        "\n",
        "If you want to play around with other data you should first check out the [list of  datasets](https://www.tensorflow.org/datasets/datasets)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pYTumpFcFZa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's use a relatively small dataset with only 11 classes for developing our\n",
        "# models. We will move to a larger set for the Sock Competition.\n",
        "# - 50k training examples, including pickled DataFrame\n",
        "data_path = 'gs://amld-datasets/zoo_img_50k'\n",
        "\n",
        "print('https://console.cloud.google.com/storage/browser/' + data_path.split('//')[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tky2lNdsxrLz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Labels are represented as integers in these examples. The \"labels.txt\" files\n",
        "# translates these integers to descriptive words.\n",
        "labels = [label.strip() for label in tf.io.gfile.GFile('{}/labels.txt'.format(data_path))]\n",
        "print('All labels in the dataset:', ' '.join(labels))\n",
        "\n",
        "# The examples re stored in a format that simply concatenates records one by\n",
        "# one. There is no information about the number of records contained. That\n",
        "# information was stored separately after generation in the \"counts.json\".\n",
        "counts = json.load(tf.io.gfile.GFile('{}/counts.json'.format(data_path)))\n",
        "print(\"Splits sizes:\", counts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJOGzXJpyJkq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This dictionary describes which features to read from the protocol buffer.\n",
        "# The protocol buffers contain additional features that we don't need below.\n",
        "feature_spec = {\n",
        "    # The label is a single number (referring to names in \"labels.txt\").\n",
        "    'label': tf.io.FixedLenFeature(shape=(), dtype=tf.int64),\n",
        "    # The images are stored as a list of numbers of type int64. Here we can\n",
        "    # specify to reshape the list on reading to a tensor of shape [64, 64].\n",
        "    'img_64': tf.io.FixedLenFeature(shape=[64, 64], dtype=tf.int64),\n",
        "}\n",
        "\n",
        "def parse_record(serialized_example):\n",
        "    features = tf.io.parse_single_example(serialized_example, feature_spec)\n",
        "    return (\n",
        "        tf.cast(features['img_64'], tf.float32) / 255,\n",
        "        tf.one_hot(features['label'], len(labels)),\n",
        "    )\n",
        "\n",
        "def make_ds(which, batch_size=100):\n",
        "    # The tf.io.gfile module provides transparent access to files on Gogole Cloud\n",
        "    # Storage (GCS).\n",
        "    ds = tf.data.TFRecordDataset(tf.io.gfile.glob('{}/{}-*'.format(data_path, which)))\n",
        "    ds = ds.map(parse_record).batch(batch_size)\n",
        "    return ds, counts[which] // batch_size\n",
        "\n",
        "ds_train, train_steps = make_ds('train')\n",
        "# Note that preloading the training shuffle buffer adds some latency when\n",
        "# accessing the data (you can try below cells without shuffling for comparison).\n",
        "ds_train = ds_train.shuffle(buffer_size=1000).repeat()\n",
        "ds_eval, eval_steps = make_ds('eval')\n",
        "\n",
        "# So we have:\n",
        "# Nr of examples in {train,eval} set = batch_size * {train,eval}_steps.\n",
        "\n",
        "train_steps, eval_steps"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7fP_bDzzAyi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The dataset is iterable. Every iteration returns a batch of tensors parsed\n",
        "# from a batch of tf.Example records. We only return the img_64 feature (x)\n",
        "# and the one-hot encoded label (y) - see return value of parse_record().\n",
        "for x, y in ds_train:\n",
        "    break\n",
        "x.shape, y.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94Ap0LKY0Gxi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Inspect some data.\n",
        "cols, rows = 7, 3\n",
        "plt.figure(figsize=(2*cols, 2*rows))\n",
        "for i in range(cols * rows):\n",
        "    plt.subplot(rows, cols, i + 1)\n",
        "    plt.imshow(x[i], cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.title(labels[y[i].numpy().argmax()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Q4ujlUy0SeQ",
        "colab_type": "text"
      },
      "source": [
        "## 2.2 Linear model\n",
        "\n",
        "We train a simple linear model from raw pixel data:\n",
        "\n",
        "$$ y = \\text{softmax}( Wx + b ) $$\n",
        "\n",
        "In this section we write a custom training loop and use basic TensorFlow operations for training. Usually you don't need this flexibility and would train the model using some abstractions (see next sections where we use Keras for achieving the same task with much less code)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0EEtCJyVR0h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We provide an initializer when creating the variable.\n",
        "W = tf.Variable(tf.random.normal(shape=(x.shape[1] * x.shape[2], y.shape[1])))\n",
        "b = tf.Variable(tf.random.normal(shape=(y.shape[1], )))\n",
        "W.shape, b.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTFza1M3VV1R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# YOUR ACTION REQUIRED:\n",
        "# Adjust the training below to use a decaying learning rate / step size instead\n",
        "# of using a fixed rate of 0.01.\n",
        "# (Using a decaying learning rate is often a good idea to make quick progress in\n",
        "#  the beginning but avoid making too big changes to already tuned parameters.)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Record values for loss and accuracy for plotting purposes.\n",
        "losses = []\n",
        "accs = []\n",
        "# Train for two epochs.\n",
        "epochs = 2\n",
        "for step, (x, y) in enumerate(ds_train):\n",
        "    if step >= epochs * train_steps:\n",
        "        break\n",
        "    # Compute predictions from input and weights.\n",
        "    with tf.GradientTape() as tape:\n",
        "        logits = tf.matmul(tf.reshape(x, (x.shape[0], -1)), W) + b\n",
        "        loss = tf.nn.softmax_cross_entropy_with_logits(y, logits)\n",
        "    losses.append(loss.numpy().mean())\n",
        "    W_grad, b_grad = tape.gradient(loss, (W, b))\n",
        "\n",
        "    # Gradient descent.\n",
        "    W.assign_add(-0.01 * W_grad)\n",
        "    b.assign_add(-0.01 * b_grad)\n",
        "\n",
        "    # Compute accuracy.\n",
        "    good_preds = tf.equal(tf.argmax(logits, axis=1), tf.argmax(y, axis=1))\n",
        "    acc = tf.reduce_mean(tf.cast(good_preds, tf.float32))\n",
        "    accs.append(acc.numpy())\n",
        "    # Prove we didn't freeze...\n",
        "    if step and step % 100 == 0:\n",
        "        print('step={:4d} loss={:2.3f} acc={:.3f}'.format(\n",
        "            step, np.mean(losses[-100:]), np.mean(accs[-100:])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgPLeaNjYGFV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot accuracy (should go up) and loss (should go down).\n",
        "# Note large variance from one batch to another.\n",
        "plt.plot(accs, 'g', label='accuracy')\n",
        "plt.legend(loc='upper right')\n",
        "plt.grid(False)\n",
        "plt.twinx().plot(losses, 'r', label='loss')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCm4AlPTVmLI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Analyze some predictions.\n",
        "cols, rows = 7, 3\n",
        "plt.figure(figsize=(2*cols, 2*rows))\n",
        "for i in range(cols * rows):\n",
        "    plt.subplot(rows, cols, i + 1)\n",
        "    plt.imshow(x[i], cmap='gray')\n",
        "    plt.axis('off')\n",
        "    pred = tf.nn.softmax(tf.matmul(tf.reshape(x[i: i + 1], (1, -1)), W) + b)\n",
        "    plt.title(labels[pred.numpy().argmax()] + '?')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAErUoWyaImf",
        "colab_type": "text"
      },
      "source": [
        "## 2.3 Keras to the rescue\n",
        "\n",
        "Keras is a clean API for defining neural networks at the layer level.\n",
        "\n",
        "A model is defined as a stack of [Keras layers](https://keras.io/layers/about-keras-layers/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WP7tyBn8aJ1O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "linear_model = tf.keras.Sequential()\n",
        "# Need to specify the input shape for the first layer.\n",
        "# Note that the batch dimension is NOT specified in the input_shape.\n",
        "linear_model.add(tf.keras.layers.Flatten(input_shape=(64, 64,)))\n",
        "# For all consecutive layers, the input shape is determined by the output shape\n",
        "# of the preceding layer.\n",
        "# A linear model is simply a single dense layer.\n",
        "linear_model.add(tf.keras.layers.Dense(len(labels), activation='softmax'))\n",
        "\n",
        "linear_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy', tf.keras.metrics.categorical_accuracy])\n",
        "\n",
        "linear_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqYgbAbvaWjc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's train the model for two epochs.\n",
        "\n",
        "# YOUR ACTION REQUIRED:\n",
        "# Use dataset from above and train and evaluate using the `.fit()` method.\n",
        "# Do you get comparable results to the previous section?\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PAFh4JWbffN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Analyze some predictions.\n",
        "cols, rows = 7, 3\n",
        "plt.figure(figsize=(2*cols, 2*rows))\n",
        "for i in range(cols * rows):\n",
        "    plt.subplot(rows, cols, i + 1)\n",
        "    plt.imshow(x[i], cmap='gray')\n",
        "    plt.axis('off')\n",
        "    pred = linear_model.predict(x[i: i + 1])[0]\n",
        "    plt.title(labels[pred.argmax()] + '?')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvIpSfV1bv4L",
        "colab_type": "text"
      },
      "source": [
        "## 2.4 Convolutional model\n",
        "\n",
        "Keras provides layers for convolution and maxpooling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NvbcSa_bxPj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Reshape(target_shape=(64, 64, 1), input_shape=(64, 64)),\n",
        "    tf.keras.layers.Conv2D(filters=32, kernel_size=(10, 10), padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(4, 4), strides=(4,4)),\n",
        "    tf.keras.layers.Conv2D(filters=64, kernel_size=(5, 5), padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(4, 4), strides=(4,4)),\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(len(labels), activation='softmax'),\n",
        "])\n",
        "\n",
        "# YOUR ACTION REQUIRED:\n",
        "# Compile + print summary of model (analogous to linear model above)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ay1IHqOlcuPU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Path where data will be stored for visualization in TensorBoard.\n",
        "# We have already started TensorBoard in the \"Start TensorBoard & tunnel\"\n",
        "# section. Go back to that section and open the link to open TensorBoard in a\n",
        "# separate tab if you have not yet done so.\n",
        "\n",
        "# You can also run this section multiple times specifying different values for\n",
        "# \"tensorboard_path\" -- TensorBoard allows you to compare the different runs.\n",
        "tensorboard_path = './tensorboard/' + time.strftime('%H:%M', time.localtime(time.time()))\n",
        "os.makedirs(tensorboard_path, exist_ok=True)\n",
        "\n",
        "# That's also the name that will be displayed in TensorBoard:\n",
        "tensorboard_path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvsRVLFrcq5s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This callback will make Keras record loss and metrics.\n",
        "# You can check out other callbacks here : https://keras.io/callbacks/\n",
        "# They can do useful stuff like \n",
        "callbacks = [\n",
        "    tf.keras.callbacks.TensorBoard(\n",
        "        log_dir=tensorboard_path, update_freq='batch'),\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lgmdONMb5tZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train the model (analogous to linear model above).\n",
        "# Note: You might want to reduce the number of steps if if it takes too long.\n",
        "# You probably want to change the runtime type (\"Runtime\" menu) to GPU! If you\n",
        "# change the runtime type then you will need to rerun the cells above because\n",
        "# the Python kernel's state is reset.\n",
        "conv_model.fit(ds_train,\n",
        "               validation_data=ds_eval,\n",
        "               steps_per_epoch=train_steps,\n",
        "               validation_steps=eval_steps,\n",
        "               epochs=3,\n",
        "               callbacks=callbacks,\n",
        "               verbose=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3uysDBX0NkX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## NOTE : If you don't see an update in TensorBoard, then restart it by re-\n",
        "##        executing the cell under \"Start TensorBoard & tunnel\". You can run\n",
        "##        those cells in a separate Colab running on the same VM (i.e. using the\n",
        "##        same runtime type) while the model is training in this Colab."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2Rfu5Ww0ESO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Analyze some predictions.\n",
        "# Compare the errors from the convolutional model with the errors from the\n",
        "# linear model...\n",
        "cols, rows = 7, 3\n",
        "plt.figure(figsize=(2*cols, 2*rows))\n",
        "for i in range(cols * rows):\n",
        "    plt.subplot(rows, cols, i + 1)\n",
        "    plt.imshow(x[i], cmap='gray')\n",
        "    plt.axis('off')\n",
        "    pred = conv_model.predict(x[i: i + 1])[0]\n",
        "    plt.title(labels[pred.argmax()] + '?')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDCRRumMCqFw",
        "colab_type": "text"
      },
      "source": [
        "## 2.5 Store/load model on Google Drive\n",
        "\n",
        "All data in the local filesystem on the VM is **ephemeral**! The VM will be deleted after some time of inactivity. Two popular options for persisting data:\n",
        "\n",
        "- Store data on some cloud storage. That's the way to got if you have large amounts of data and/or later need to access it from a cloud environment. But you also first have to register a cloud account and"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5E4keWeliXm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.makedirs(models_path, exist_ok=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V94tLWcEJDeI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save model as Keras model.\n",
        "keras_path = os.path.join(models_path, 'linear.h5')\n",
        "linear_model.save(keras_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJj4acwemWDy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Keras model is a single file.\n",
        "!ls -hl \"$keras_path\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7voxj90AMWXa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.load_model(keras_path)\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-2bz6nEJEl_",
        "colab_type": "text"
      },
      "source": [
        "# 3 Sock competition\n",
        "\n",
        "\n",
        "The models that we used in the earlier sections were intentionally kept very simple and have not been optimized at all.\n",
        "\n",
        "In this section we will first load a dataset with some more classes to make the problem more interesting. Your task is then to develop a better model to achieve maximum accuracy ont he evaluation set.\n",
        "\n",
        "Start with simple things (tuning batch size, learning rate, optimizer), then add more layers (batch norm, more/less convolutions). When you think you have a good combination, try increasing the training time to see where you can get."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hymTJAoJF_3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## - 4.1M training examples, without pickled DataFrame\n",
        "animals_data_path = 'gs://amld-datasets/animals_img'\n",
        "\n",
        "print('https://console.cloud.google.com/storage/browser/' + data_path.split('//')[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXsH2JgLTEbF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "animals_labels = [label.strip() for label in tf.io.gfile.GFile('{}/labels.txt'.format(data_path))]\n",
        "print('All labels in the dataset:', ' '.join(labels))\n",
        "\n",
        "animals_counts = json.load(tf.io.gfile.GFile('{}/counts.json'.format(data_path)))\n",
        "print(\"Splits sizes:\", counts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pHwYvj3VaPz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# (Uses functions defined under \"2.1 Read data\").\n",
        "\n",
        "def make_ds(which, batch_size=100):\n",
        "    # The tf.io.gfile module provides transparent access to files on Gogole Cloud\n",
        "    # Storage (GCS).\n",
        "    ds = tf.data.TFRecordDataset(tf.io.gfile.glob('{}/{}-*'.format(animals_data_path, which)))\n",
        "    ds = ds.map(parse_record).batch(batch_size)\n",
        "    return ds, animals_counts[which] // batch_size\n",
        "\n",
        "animals_ds_train, animals_train_steps = make_ds('train')\n",
        "animals_ds_train = animals_ds_train.shuffle(1000).repeat()\n",
        "animals_ds_eval, animals_eval_steps = make_ds('eval')\n",
        "\n",
        "animals_train_steps, animals_eval_steps"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuMKkP-DV7um",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for x, y in animals_ds_train:\n",
        "    break\n",
        "x.shape, y.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iuG-iypVmnp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualize some data. Note how the increased number of classes makes the\n",
        "# problem considerably more complicated...\n",
        "cols, rows = 7, 3\n",
        "plt.figure(figsize=(2*cols, 2*rows))\n",
        "for i in range(cols * rows):\n",
        "    plt.subplot(rows, cols, i + 1)\n",
        "    plt.imshow(x[i], cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.title(labels[y[i].numpy().argmax()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AX00uIh-YJ0e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# YOUR ACTION REQUIRED:\n",
        "#\n",
        "# Build a model by stacking some Keras layers. Note that using the example\n",
        "# configuration from above yields already 63% accuracy (convolutional model).\n",
        "#\n",
        "# While waiting for training, you can walk through the bonus section below\n",
        "# (make another copy of the Colab if necessary)."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xm3XfMvkgFKO",
        "colab_type": "text"
      },
      "source": [
        "# 4 Bonus: TensorFlow.js\n",
        "\n",
        "In this section we'll convert our models from last section to TensorFlow.js models and then write a mini web site that loads the converted model for live inference.\n",
        "\n",
        "First read a bit about basic concepts in TensorFlow.js:\n",
        "https://js.tensorflow.org/tutorials/core-concepts.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VogZyTDRZwQn",
        "colab_type": "text"
      },
      "source": [
        "### 4.1 Basics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qp8mXdaBy2rC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Getting the data of a tensor in TensorFlow.js : Use the async .data() method\n",
        "# to show the output in the \"output\" element.\n",
        "# See output in javascript console (e.g. Chrome developer tools).\n",
        "\n",
        "# Alternatively, you can also copy'n'paste the code into a CodePen:\n",
        "# https://codepen.io/andreassteiner/pen/BedqJW?editors=1011\n",
        "%%html\n",
        "<script src=\"https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@0.14.1/dist/tf.min.js\"></script>\n",
        "<pre id=\"output\"></pre>\n",
        "<script>\n",
        "  let output = document.getElementById('output')\n",
        "  let t = tf.tensor([1, 2, 3])\n",
        "  output.textContent = t\n",
        "  // YOUR ACTION REQUIRED:\n",
        "  // Use \"t.data()\" to append the tensor's data values to \"output.textContent\".\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-KQ05ww6zCY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get top 3 predictions in TensorFlow.\n",
        "preds = tf.constant([0.1, 0.5, 0.2, 0.0])\n",
        "topk = tf.math.top_k(preds, 3)\n",
        "for idx, value in zip(topk.indices.numpy(), topk.values.numpy()):\n",
        "    print('idx', idx, 'value', value)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tUk3AAl7qG1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Implement the same top 3 functionality in TensorFlow.js, showing the output\n",
        "# in the \"output\" element.\n",
        "# See https://js.tensorflow.org/api/latest/index.html#topk\n",
        "%%html\n",
        "<script src=\"https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@0.14.1/dist/tf.min.js\"></script>\n",
        "<pre id=\"output\"></pre>\n",
        "<script>\n",
        "  let output = document.getElementById('output')\n",
        "  let preds = tf.tensor([0.1, 0.5, 0.2, 0.0])\n",
        "  // YOUR ACTION REQUIRED:\n",
        "  // Use tf.topk() to get top 3 predictions in \"preds\" and append both the\n",
        "  // index and the value of these predictions to \"output\".\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiROzUvkZyrl",
        "colab_type": "text"
      },
      "source": [
        "### 4.2 Convert Model\n",
        "\n",
        "We can convert the Keras model into TensorFlow.js format using the Python package `tensorflowjs`.\n",
        "\n",
        "Read more about importing Keras models:\n",
        "https://js.tensorflow.org/tutorials/import-keras.html\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6YIzCLo9gOTp",
        "colab": {}
      },
      "source": [
        "# Install extra package\n",
        "!pip install -q tensorflowjs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdWRdec1aNUq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Specify directory where to store model.\n",
        "# BTW : Note the \"Files\" tabe on the left side (where we also have \"Table of\n",
        "# contents\"). After executing this cell you should see the new \"tfjs\" directory.\n",
        "tfjs_model_path = './tfjs/model'\n",
        "!mkdir -p \"$tfjs_model_path\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isxNzEE-6lEM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert model.\n",
        "import tensorflowjs as tfjs\n",
        "tfjs.converters.save_keras_model(conv_model, tfjs_model_path)\n",
        "!ls -lh \"$tfjs_model_path\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yK3ZcgRxasGv",
        "colab_type": "text"
      },
      "source": [
        "### 4.3 Run http Server\n",
        "\n",
        "By copying together the content of the two `%%html` cells (without the leading `%%html`!) you can now create a fully functional mini web app that handles user input and performs predictions on-device.\n",
        "\n",
        "We store the web page in `./tfjs/index.html` and then use `python3 -m http.server` to serve both the html and the model files. The HTTP port is then forwarded to a public address using [ngrok](https://ngrok.com)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m12iXwlzaglF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Append the content of the two html cells (without the \"%%html\" line) in this\n",
        "# Colab below and run the cell. It will create a file \"index.html\" - you can\n",
        "# verify this in the \"Files\" tab on the right.\n",
        "%%writefile ./tfjs/index.html\n",
        "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1, user-scalable=no\">\n",
        "<canvas width=\"256\" height=\"256\" id=\"canvas\" style=\"border:1px solid black\"></canvas><br />\n",
        "<button id=\"clear\">clear</button><br />\n",
        "<pre id=\"output\"></pre>\n",
        "<script>\n",
        "  window.onerror = function(msg, url, line, col, error) {\n",
        "    alert(\"Error: \" + msg + \"\\nurl: \" + url + \"\\nline: \" + line + '\\nerror: ' + error);\n",
        "  }\n",
        "</script>\n",
        "<script>\n",
        "  let upscaleFactor = 4, halfPenSize = 2\n",
        "  let canvas = document.getElementById('canvas')\n",
        "  let output = document.getElementById('output')\n",
        "  let ctx = canvas.getContext('2d')\n",
        "  let img_64 = new Uint8Array(64*64)\n",
        "  let dragging = false\n",
        "  let timeout\n",
        "  let predict = () => {\n",
        "    google.colab.kernel.invokeFunction('amld.predict', [Array.from(img_64)], {}).then(\n",
        "        obj => output.textContent = obj.data['application/json'].result)\n",
        "  }\n",
        "  const getPos = e => {\n",
        "    let x = e.offsetX, y = e.offsetY\n",
        "    if (e.touches) {\n",
        "      const rect = canvas.getBoundingClientRect()\n",
        "      x = e.touches[0].clientX - rect.left\n",
        "      y = e.touches[0].clientY - rect.left\n",
        "    }\n",
        "    return {\n",
        "      x: Math.floor((x - 2*halfPenSize*upscaleFactor/2)/upscaleFactor),\n",
        "      y: Math.floor((y - 2*halfPenSize*upscaleFactor/2)/upscaleFactor),\n",
        "    }\n",
        "  }\n",
        "  const handler = e => {\n",
        "    const { x, y } = getPos(e)\n",
        "    ctx.fillStyle = 'black'\n",
        "    ctx.fillRect(x*upscaleFactor, y*upscaleFactor,\n",
        "                 2*halfPenSize*upscaleFactor, 2*halfPenSize*upscaleFactor)\n",
        "    for (let yy = y - halfPenSize; yy < y + halfPenSize; yy++)\n",
        "      for (let xx = x - halfPenSize; xx < x + halfPenSize; xx++)\n",
        "        img_64[64*Math.min(63, Math.max(0, yy)) + Math.min(63, Math.max(0, xx))] = 1\n",
        "    clearTimeout(timeout)\n",
        "    timeout = setTimeout(predict, 500)\n",
        "  }\n",
        "  canvas.addEventListener('touchstart', e => {dragging=true; handler(e)})\n",
        "  canvas.addEventListener('touchmove', e => {e.preventDefault(); dragging && handler(e)})\n",
        "  canvas.addEventListener('touchend', () => dragging=false)\n",
        "  canvas.addEventListener('mousedown', e => {dragging=true; handler(e)})\n",
        "  canvas.addEventListener('mousemove', e => {dragging && handler(e)})\n",
        "  canvas.addEventListener('mouseup', () => dragging=false)\n",
        "  canvas.addEventListener('mouseleave', () => dragging=false)\n",
        "  document.getElementById('clear').addEventListener('click', () => {\n",
        "    ctx.fillStyle = 'white'\n",
        "    ctx.fillRect(0, 0, 64*upscaleFactor, 64*upscaleFactor)\n",
        "    output.textContent = ''\n",
        "    img_64 = new Uint8Array(64*64)\n",
        "  })\n",
        "</script>\n",
        "<script src=\"https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.0.0/dist/tf.min.js\"></script>\n",
        "<script>\n",
        "  const labels = [\"camel\", \"crocodile\", \"dolphin\", \"elephant\", \"flamingo\", \"giraffe\", \"kangaroo\", \"lion\", \"monkey\", \"penguin\", \"rhinoceros\"]\n",
        "  const modelPath = './model/model.json'\n",
        "  let model = null\n",
        "  tf.loadLayersModel(modelPath).then(response => model = response)\n",
        "  predict = () => {\n",
        "    const preds = model.predict(tf.tensor(img_64).reshape([1, 64, -1]))\n",
        "    const { values, indices } = tf.topk(preds, 3)\n",
        "    Promise.all([values.data(), indices.data()]).then(data => {\n",
        "      const [ values, indices ] = data\n",
        "      output.textContent = ''\n",
        "      values.forEach((v, i) => output.textContent +=  `${labels[indices[i]]} : ${v.toFixed(3)}\\n`)\n",
        "    })\n",
        "  }\n",
        "</script>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TeQ34tArf3w-",
        "colab": {}
      },
      "source": [
        "# Forwarding of port local http server using https://ngrok.com\n",
        "# (You can skip this cell if you already downloaded ngrok under 1.3)\n",
        "\n",
        "# Download & unzip ngrok\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip -o ngrok-stable-linux-amd64.zip\n",
        "!ls -lh ./ngrok"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pXBsA5tZf6U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make sure ngrok is downloaded.\n",
        "assert os.system('./ngrok --help') == 0\n",
        "\n",
        "# Then start a mini web server at a random port...\n",
        "import random\n",
        "port = random.randint(1000, 2**16)\n",
        "\n",
        "!pkill ngrok\n",
        "!kill $(ps x | grep -v grep | grep http.server | awk '{print $1}') 2>/dev/null\n",
        "\n",
        "get_ipython().system_raw(\n",
        "    'cd ./tfjs && python3 -m http.server {} &'\n",
        "    .format(port)\n",
        ")\n",
        "\n",
        "# ...and forward the port using ngrok.\n",
        "get_ipython().system_raw('./ngrok http {} &'.format(port))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcOW2pxypAqh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the public address from localhost:4040 (ngrok's web interface).\n",
        "import time, urllib\n",
        "time.sleep(1)  # Give ngrok time to startup.\n",
        "ngrok_data = json.load(urllib.request.urlopen('http://localhost:4040/api/tunnels'))\n",
        "ngrok_data['tunnels'][0]['public_url']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5MXOBH3kkYj",
        "colab_type": "text"
      },
      "source": [
        "Note: If you don't see any predictions, check the Browser's error console. If you see a message like \"Provided weight data has no target variable\" then it is likely due to weight names getting mixed up when reloading a saved model from disk. In that case, either convert a model trained in the current session - not loaded via `tf.keras.models.load_model()` - or restart the kernel and reload from disk using `tf.keras.models.load_model()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ug9gk1oma-64",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# You can connect to this external address using your mobile phone!\n",
        "# Once the page is loaded you can turn on flight modus and verify that\n",
        "# predictions are really generated on-device :-)\n",
        "!pip install -q qrcode\n",
        "import qrcode\n",
        "qrcode.make(ngrok_data['tunnels'][0]['public_url'])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}